{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0b6d5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Lorem Ipsum is just a random txt that devs use as a placeholder for multiple things (especially web developping) when you don't have the real text and just want to test your functionnality. Put a Lorem Ipsum of 3 paragraphs in a txt file using python, each paragraph delimited by two new line.\n",
    "# Lorem ipsum de 3 paragraphes générés avec le site partagé dans le cours\n",
    "lorem_ipsum_text = \"\"\"\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam tincidunt tincidunt dignissim. Quisque luctus leo quam, et finibus quam venenatis ut. Cras finibus quis leo ac semper. Sed at nisl at mi dignissim sagittis euismod id nibh. Nulla ultricies aliquam metus at sagittis. Vivamus dignissim quam nec mattis posuere. Nullam ultricies a libero at posuere. Suspendisse potenti. Ut dignissim ligula mi, at tristique ex ultrices feugiat. Integer rutrum, mauris id aliquam sodales, leo elit cursus leo, non feugiat odio dolor sit amet diam. Sed consectetur bibendum justo, at placerat turpis.\n",
    "\n",
    "Suspendisse id pellentesque lectus. Suspendisse dignissim vehicula mattis. Duis vel mi orci. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Integer vehicula tortor eu turpis gravida, tempus euismod lectus porttitor. Nulla ac pretium sapien. Vivamus nec vestibulum augue, eu commodo orci. Etiam molestie lorem nec nisl pharetra aliquam et eget quam. Morbi luctus vitae erat ac mollis. Ut porttitor neque eget turpis tristique hendrerit. Sed at ante augue.\n",
    "\n",
    "Vivamus tempus aliquet ullamcorper. Aliquam dapibus vitae eros a consectetur. Cras et semper lorem. Aenean arcu turpis, elementum sed urna nec, hendrerit interdum lacus. Phasellus volutpat odio ac ex pretium, sit amet malesuada nisi ultricies. Phasellus quis nulla bibendum, dapibus dui in, suscipit lorem. Duis ultricies justo ante, porttitor ultrices neque tempus vel. Nullam cursus molestie est, id gravida mi commodo ac. Nunc pulvinar, ipsum a suscipit imperdiet, metus dolor hendrerit magna, eleifend suscipit lacus ipsum ac eros. Proin in tincidunt elit, quis condimentum mi. Aenean pretium molestie mauris nec faucibus. Mauris mattis, felis scelerisque congue faucibus, lectus metus facilisis velit, non luctus lacus est eu orci. Sed auctor ex metus, at efficitur nisi scelerisque ac. Nam vulputate ipsum nec tellus fermentum, vitae blandit quam lobortis. Pellentesque at purus ac elit egestas pulvinar. Proin suscipit mi vitae est tristique, sit amet porttitor magna sodales.\n",
    "\"\"\"\n",
    "\n",
    "with open('C:/Users/celes/OneDrive/Documents/M1/S2/Infrastructures/NoSQL/lorem_ipsum.txt', 'w') as file:\n",
    "    file.write(lorem_ipsum_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30987c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: Update the txt file by removing the first paragraph.\n",
    "with open('C:/Users/celes/OneDrive/Documents/M1/S2/Infrastructures/NoSQL/lorem_ipsum.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "lines.pop(0)\n",
    "\n",
    "with open('C:/Users/celes/OneDrive/Documents/M1/S2/Infrastructures/NoSQL/lorem_ipsum.txt', 'w') as file:\n",
    "    for line in lines:\n",
    "        file.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f545030b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'authors': ['Yann LeCun', 'Yoshua Bengio', 'Geoffrey Hinton'], 'title': 'Deep Learning', 'affiliations': ['Université de Montréal']}\n"
     ]
    }
   ],
   "source": [
    "# 3: Create a dict from the paper of lecun et al. and goodfellow et al. with authors, title, affiliations.\n",
    "lecun_paper = {\"authors\" : [\"Yann LeCun\",\"Yoshua Bengio\",\"Geoffrey Hinton\"],\n",
    "         \"title\" : \"Deep Learning\",\n",
    "         \"affiliations\" : [\"Université de Montréal\"]}\n",
    "goodfellow_paper = {\"authors\" : [\"Ian J. Goodfellow\",\"Jean Pouget-Abadie\",\"Mehdi Mirza\",\"Bing Xu\",\"David Warde-Farley\",\"Sherjil Ozair\",\"Aaron Courville\",\"Yoshua Bengio\"],\n",
    "         \"title\" : \"Generative Adversarial Networks\",\n",
    "         \"affiliations\" : [\"Cornell University\"]}\n",
    "\n",
    "print(lecun_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7914e228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'authors': ['Yann LeCun', 'Yoshua Bengio', 'Geoffrey Hinton'], 'title': 'Deep Learning', 'affiliations': ['Université de Montréal']}\n",
      "{'authors': ['Ian J. Goodfellow', 'Jean Pouget-Abadie', 'Mehdi Mirza', 'Bing Xu', 'David Warde-Farley', 'Sherjil Ozair', 'Aaron Courville', 'Yoshua Bengio'], 'title': 'Generative Adversarial Networks', 'affiliations': ['Cornell University']}\n"
     ]
    }
   ],
   "source": [
    "# 4: Save the previously created dict in the JSON format and load it back.\n",
    "import json\n",
    "with open('C:/Users/celes/OneDrive/Documents/M1/S2/Infrastructures/NoSQL/lecun_paper.json', 'w') as fp:\n",
    "    json.dump(lecun_paper, fp)\n",
    "\n",
    "with open('C:/Users/celes/OneDrive/Documents/M1/S2/Infrastructures/NoSQL/goodfellow_paper.json', 'w') as fp:\n",
    "    json.dump(goodfellow_paper, fp)\n",
    "\n",
    "# Chargement des dictionnaires depuis les fichiers JSON\n",
    "with open('C:/Users/celes/OneDrive/Documents/M1/S2/Infrastructures/NoSQL/lecun_paper.json', 'r') as fp:\n",
    "    loaded_lecun_paper = json.load(fp)\n",
    "\n",
    "with open('C:/Users/celes/OneDrive/Documents/M1/S2/Infrastructures/NoSQL/goodfellow_paper.json', 'r') as fp:\n",
    "    loaded_goodfellow_paper = json.load(fp)\n",
    "\n",
    "print(loaded_lecun_paper)\n",
    "print(loaded_goodfellow_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f83bf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x80\\x04\\x95\\x87\\x00\\x00\\x00\\x00\\x00\\x00\\x00}\\x94(\\x8c\\x07authors\\x94]\\x94(\\x8c\\nYann LeCun\\x94\\x8c\\rYoshua Bengio\\x94\\x8c\\x0fGeoffrey Hinton\\x94e\\x8c\\x05title\\x94\\x8c\\rDeep Learning\\x94\\x8c\\x0caffiliations\\x94]\\x94\\x8c\\x18Universit\\xc3\\xa9 de Montr\\xc3\\xa9al\\x94au.'\n"
     ]
    }
   ],
   "source": [
    "# 5: Save the previously created dict in the pickle format. Try to open manually (i.e with a text editor), is it human readable ?\n",
    "import pickle\n",
    "\n",
    "with open('C:/Users/celes/OneDrive/Documents/M1/S2/Infrastructures/NoSQL/lecun_paper.pickle', 'wb') as fp:\n",
    "    pickle.dump(lecun_paper, fp)\n",
    "\n",
    "with open('C:/Users/celes/OneDrive/Documents/M1/S2/Infrastructures/NoSQL/goodfellow_paper.pickle', 'wb') as fp:\n",
    "    pickle.dump(goodfellow_paper, fp)\n",
    "\n",
    "#Pour voir si c'est lisible :\n",
    "with open('C:/Users/celes/OneDrive/Documents/M1/S2/Infrastructures/NoSQL/lecun_paper.pickle', 'rb') as fp:\n",
    "    content = fp.read()\n",
    "\n",
    "print(content)\n",
    "# On constate donc au vu de l'output que ce n'est pas interprétable tel quel par un humain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a04806c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<note>\n",
      "  <date>2015-09-01</date>\n",
      "  <hour>08:30</hour>\n",
      "  <to>Tove</to>\n",
      "  <from>Jani</from>\n",
      "  <body>Don't forget me this weekend!</body>\n",
      "</note>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6.1: Parse the xml_file2 in the same way as in the lecture.\n",
    "import lxml.etree\n",
    "\n",
    "xml_file2 = \"C:/Users/celes/OneDrive/Documents/M1/S2/Infrastructures/NoSQL/data/Chap2/xml_file2.nxml\"\n",
    "root = lxml.etree.parse(xml_file2)\n",
    "print(lxml.etree.tostring(root, encoding=\"unicode\", pretty_print=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25c18c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "# 6.2: put infos in a dict and save it in a json file.\n",
    "notes = []\n",
    "\n",
    "for note_elem in root.findall('note'):\n",
    "    note_data = {}\n",
    "    note_data['date'] = note_elem.find('date').text\n",
    "    note_data['hour'] = note_elem.find('hour').text\n",
    "    note_data['to'] = note_elem.find('to').text\n",
    "    note_data['from'] = note_elem.find('from').text\n",
    "    note_data['body'] = note_elem.find('body').text\n",
    "\n",
    "    notes.append(note_data)\n",
    "\n",
    "with open('C:/Users/celes/OneDrive/Documents/M1/S2/Infrastructures/NoSQL/xml_data.json', 'w') as fp:\n",
    "    json.dump(xml_data, fp, indent=4)\n",
    "    \n",
    "with open('C:/Users/celes/OneDrive/Documents/M1/S2/Infrastructures/NoSQL/xml_data.json', 'w') as fp:\n",
    "    json.dump(xml_data, fp)\n",
    "with open('C:/Users/celes/OneDrive/Documents/M1/S2/Infrastructures/NoSQL/xml_data.json', 'r') as file:\n",
    "    contents = json.load(file)\n",
    "    print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c54f7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7: Download an image of your choice and save it in either jpg or png.\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "im = Image.open(requests.get(\"https://upload.wikimedia.org/wikipedia/commons/3/3b/Albrecht_durer_heavenly_body_in_the_night_sky.jpg\", stream=True).raw)\n",
    "im.save(\"C:/Users/celes/OneDrive/Documents/M1/S2/Infrastructures/NoSQL/Dürer.png\", \"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08fbdf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9 : From the data/Chap2/data_world.json file, delete the key of your choice and save the new dict as data_world_cleaned.json.\n",
    "import json\n",
    "import os\n",
    "\n",
    "with open('C:/Users/celes/OneDrive/Documents/M1/S2/Infrastructures/NoSQL/data/Chap2/data_world.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "for book in data:\n",
    "    if 'subtitle' in book:\n",
    "        del book['subtitle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83a3d915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "public | irregular | 4961\n",
      "public | R/P1D | 5\n",
      "public | R/P1M | 3\n",
      "public | Unknown | 29\n",
      "public | R/PT1S | 1\n",
      "public | R/P3M | 1\n"
     ]
    }
   ],
   "source": [
    "#10 : From the data/Chap2/data_world.json file, create the co-occurence matrix between \"accessLevel\" and \"accrualPeriodicity\".\n",
    "\n",
    "matrix = {}\n",
    "\n",
    "with open('C:/Users/celes/OneDrive/Documents/M1/S2/Infrastructures/NoSQL/data/Chap2/data_world.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "for book in data:\n",
    "    access_level = book['accessLevel']\n",
    "    if 'accrualPeriodicity' in book:\n",
    "        accrual_periodicity = book['accrualPeriodicity']\n",
    "    else:\n",
    "        accrual_periodicity = 'Unknown'\n",
    "    if access_level not in matrix:\n",
    "        matrix[access_level] = {}\n",
    "    if accrual_periodicity not in matrix[access_level]:\n",
    "        matrix[access_level][accrual_periodicity] = 0\n",
    "    matrix[access_level][accrual_periodicity] += 1\n",
    "\n",
    "for access_level in matrix:\n",
    "    for accrual_periodicity in matrix[access_level]:\n",
    "        count = matrix[access_level][accrual_periodicity]\n",
    "        print(f'{access_level} | {accrual_periodicity} | {count}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
